# SPDX-License-Identifier: MIT OR Apache-2.0
# SPDX-FileCopyrightText: The Ferrocene Developers

# NOTE: if you add new targets here make sure to also change
# `ferrocene/packages.toml` to include it in new releases.

---
version: 2.1

# Parameter values are determined by `calculate-parameters.py` dynamically
# before the build starts. The script must be able to calculate the value of
# ALL parameters, otherwise it will error out.
#
# Parameters with the following prefixes are supported:
#
# * `docker-image-tag--`: calculates the appropriate tag for the named image.
# * `docker-repository-url--`: calculates the URL of an ECR repository
#
parameters:
  docker-image-tag--x86_64--ubuntu-20:
    type: string
    default: ""
  docker-image-tag--aarch64--ubuntu-20:
    type: string
    default: ""
  docker-image-tag--x86_64--ubuntu-24:
    type: string
    default: ""
  docker-image-tag--aarch64--ubuntu-24:
    type: string
    default: ""
  docker-image-rebuild--ci-docker-images--x86_64--ubuntu-20:
    type: boolean
    default: false
  docker-image-rebuild--ci-docker-images--aarch64--ubuntu-20:
    type: boolean
    default: false
  docker-image-rebuild--ci-docker-images--x86_64--ubuntu-24:
    type: boolean
    default: false
  docker-image-rebuild--ci-docker-images--aarch64--ubuntu-24:
    type: boolean
    default: false
  docker-repository-url--ci-docker-images:
    type: string
    default: ""
  llvm-rebuild--x86_64-unknown-linux-gnu:
    type: boolean
    default: false
  llvm-rebuild--aarch64-unknown-linux-gnu:
    type: boolean
    default: false
  llvm-rebuild--aarch64-apple-darwin:
    type: boolean
    default: false
  llvm-rebuild--x86_64-pc-windows-msvc:
    type: boolean
    default: false
  targets--x86_64-unknown-linux-gnu--build:
    type: string
    default: ""
  targets--x86_64-unknown-linux-gnu--self-test:
    type: string
    default: ""
  targets--x86_64-unknown-linux-gnu--std:
    type: string
    default: ""
  targets--aarch64-unknown-linux-gnu--build:
    type: string
    default: ""
  targets--aarch64-unknown-linux-gnu--self-test:
    type: string
    default: ""
  targets--aarch64-apple-darwin--build:
    type: string
    default: ""
  targets--aarch64-apple-darwin--self-test:
    type: string
    default: ""
  targets--x86_64-pc-windows-msvc--build:
    type: string
    default: ""
  targets--x86_64-pc-windows-msvc--self-test:
    type: string
    default: ""

orbs:
  aws-cli: circleci/aws-cli@4.0
  win: circleci/windows@5.0

jobs:
  # Container dedicated to running quick checks for each commit pushed in open
  # PRs and personal branches. The job must balance providing quick feedback
  # and providing useful feedback, focusing on catching the most common errors
  # as soon as possible.
  #
  # It's fine if this job only runs a small subset of the test suite: the full
  # test suite for all the supported targets will be run when bors tries to
  # merge the PR anyway.
  commit-checks:
    executor: docker-x86_64-ubuntu-24
    resource_class: large # 4-core
    environment:
      FERROCENE_CUSTOM_LLVM: /usr/lib/llvm-17
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      SCRIPT: |
        ./x.py test tidy
        ./x.py check library compiler/rustc
        ./x.py run ferrocene/tools/traceability-matrix
    steps:
      - aws-oidc-auth
      - ferrocene-checkout:
          llvm-subset: true
      - run:
          name: Check whether git conflict markers are present
          command: ferrocene/ci/scripts/detect-conflict-markers.py
      - run:
          name: Perform licensing checks
          command: reuse --include-submodules lint
      - ferrocene-ci

  # Container dedicated to running ad-hoc tests that don't depend on an
  # individual target. If you have a test you don't know where to run it, this
  # is the place for it.
  misc-checks:
    executor: docker-x86_64-ubuntu-20
    resource_class: medium # 2-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      SCRIPT: |
        ./x.py test $(ferrocene/ci/split-tasks.py test:misc-checks)
    steps:
      - aws-oidc-auth
      - ferrocene-checkout:
          llvm-subset: true
      - run:
          name: Perform licensing checks
          command: reuse --include-submodules lint
      - ferrocene-ci

  # x86_64-unknown-linux-gnu jobs

  x86_64-linux-build:
    executor: docker-x86_64-ubuntu-20
    resource_class: xlarge # 8-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      FERROCENE_TARGETS: aarch64-unknown-linux-gnu
      SCRIPT: |
        ./ferrocene/ci/scripts/llvm_cache.py download
        ./x.py --stage 2 build library src/tools/rustdoc
        ./x.py --stage 1 build src/tools/rustdoc
    steps: [ferrocene-job-build]

  x86_64-linux-docs:
    executor: docker-x86_64-ubuntu-20
    resource_class: large # 4-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      RUST_CONFIGURE_ARGS: |
        --set
        ferrocene.test-outcomes=custom
        --set
        ferrocene.test-outcomes-dir=/tmp/test-outcomes
      SCRIPT: |
        ferrocene/ci/scripts/fetch-test-outcomes.sh
        # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
        # Run dist before test to make sure the tarballs we test are uploaded
        # to CI beforehand, for manual inspection in case of failures.
        ./x.py --stage 2 dist $(ferrocene/ci/split-tasks.py dist:docs)
        ./x.py --stage 2 test $(ferrocene/ci/split-tasks.py test:docs)
    steps:
      - ferrocene-job-dist:
          restore-from-job: x86_64-linux-build

  x86_64-linux-dist:
    executor: docker-x86_64-ubuntu-20
    resource_class: xlarge # 8-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      SCRIPT: |
        # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
        ./x.py --stage 2 dist $(ferrocene/ci/split-tasks.py dist)
    steps:
      - ferrocene-job-dist:
          restore-from-job: x86_64-linux-build

  x86_64-linux-dist-tools:
    executor: docker-x86_64-ubuntu-20
    resource_class: xlarge # 8-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      SCRIPT: |
        # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
        ./x.py --stage 2 dist $(ferrocene/ci/split-tasks.py dist:tools)
    steps:
      - ferrocene-job-dist:
          restore-from-job: x86_64-linux-build

  x86_64-linux-dist-targets:
    executor: docker-x86_64-ubuntu-20
    resource_class: large # 4-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      FERROCENE_TARGETS: << pipeline.parameters.targets--x86_64-unknown-linux-gnu--std >>
      SCRIPT: |
        ./x.py --stage 2 dist rust-std
    steps:
      - ferrocene-job-dist:
          qnx: true
          restore-from-job: x86_64-linux-build

  x86_64-linux-dist-src:
    executor: docker-x86_64-ubuntu-20
    resource_class: medium # 2-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      SCRIPT: |
        ./x.py --stage 2 dist $(ferrocene/ci/split-tasks.py dist:src)
    steps:
      - ferrocene-job-dist:
          restore-from-job: x86_64-linux-build
          # We need the whole LLVM clone to be able to include the full source
          # code into the tarball we ship to customers.
          llvm-subset: false

  wasm-dist-oxidos:
    executor: docker-x86_64-ubuntu-20
    resource_class: large # 4-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      FERROCENE_TARGETS: wasm32-unknown-unknown
      SCRIPT: |
        ./x.py --stage 2 dist $(ferrocene/ci/split-tasks.py dist:oxidos)
    steps:
      - ferrocene-job-dist:
          restore-from-job: x86_64-linux-build

  x86_64-linux-generic-test-container:
    executor: docker-x86_64-ubuntu-20
    parameters:
      job:
        type: string
      resource-class:
        type: string
    resource_class: << parameters.resource-class >>
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      SCRIPT: |
        # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
        ./x.py --stage 2 test $(ferrocene/ci/split-tasks.py << parameters.job >>) --ferrocene-test-one-crate-per-cargo-call
    steps:
      - ferrocene-job-test-container:
          restore-from-job: x86_64-linux-build

  aarch64-linux-generic-test-vm:
    executor: linux-vm
    parameters:
      job:
        type: string
      resource-class:
        type: string
    resource_class: << parameters.resource-class >>
    environment:
      FERROCENE_HOST: ""
      FERROCENE_TARGETS: aarch64-unknown-ferrocenecoretest
      # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
      SCRIPT: |
        TEST_DEVICE_ADDR=127.0.0.1:12345 ./x.py --stage 2 test $(ferrocene/ci/split-tasks.py << parameters.job >>) --ferrocene-test-one-crate-per-cargo-call

    steps:
      - ferrocene-job-test-vm:
          docker-image-tag: << pipeline.parameters.docker-image-tag--x86_64--ubuntu-20 >>
          run-emulator-docker-image-tag: << pipeline.parameters.docker-image-tag--x86_64--ubuntu-20 >>
          restore-from-job: x86_64-linux-build
          emulator-script: ferrocene/ci/scripts/emulated-aarch64-test-runner.sh

  x86_64-linux-traceability-matrix:
    executor: docker-x86_64-ubuntu-20
    resource_class: medium # 2-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      RUST_CONFIGURE_ARGS: |
        --set
        ferrocene.test-outcomes=custom
        --set
        ferrocene.test-outcomes-dir=/tmp/test-outcomes
      SCRIPT: |
        ferrocene/ci/scripts/fetch-test-outcomes.sh
        ./x.py run ferrocene/tools/traceability-matrix
    steps:
      - aws-oidc-auth
      - ferrocene-checkout:
          llvm-subset: true
      - ferrocene-ci
      - store_artifacts:
          path: build/x86_64-unknown-linux-gnu/ferrocene/traceability-matrix.html
          destination: reports

  x86_64-linux-test-library-std:
    executor: linux-vm
    resource_class: large # 4-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      # Standard library tests need IPv6, which is not available in container
      # jobs. Because of that we need to run *just* standard library tests in a
      # virtual machine.
      # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
      SCRIPT: ./x.py --stage 2 test $(ferrocene/ci/split-tasks.py test:library-std) --ferrocene-test-one-crate-per-cargo-call
    steps:
      - aws-oidc-auth
      - ferrocene-job-test-vm:
          docker-image-tag: << pipeline.parameters.docker-image-tag--x86_64--ubuntu-20 >>
          run-emulator-docker-image-tag: << pipeline.parameters.docker-image-tag--x86_64--ubuntu-20 >>
          restore-from-job: x86_64-linux-build

  x86_64-linux-llvm:
    executor: docker-x86_64-ubuntu-20
    resource_class: xlarge # 8-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      SCRIPT: ferrocene/ci/scripts/llvm_cache.py prepare
      # This tries to strike a balance between the highest concurrency possible
      # and not running out of memory during a build. If building LLVM fails
      # due to the OOM killer killing the build, decrease this number.
      LLVM_BUILD_PARALLELISM: 18
    steps:
      - when:
          condition: << pipeline.parameters.llvm-rebuild--x86_64-unknown-linux-gnu >>
          steps:
            - aws-oidc-auth
            - ferrocene-checkout
            - ferrocene-ci
      - run:
          name: Empty step to make sure the job always has steps
          command: echo

  x86_64-linux-self-test:
    executor: docker-x86_64-ubuntu-20
    resource_class: small # 1-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      FERROCENE_TARGETS: << pipeline.parameters.targets--x86_64-unknown-linux-gnu--self-test >>
    steps:
      - ferrocene-git-shallow-clone:
          depth: 1
      - aws-oidc-auth
      - setup-qnx-toolchain: {}
      - run:
          name: Download dist artifacts and run the self-test tool
          command: ferrocene/ci/scripts/run-self-test.sh

  x86_64-qnx-generic-test-vm:
    executor: linux-vm
    parameters:
      job:
        type: string
      resource-class:
        type: string
    resource_class: << parameters.resource-class >>
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      FERROCENE_TARGETS: x86_64-pc-nto-qnx710
      SCRIPT: |
        set +u; source ./qnx710-472/qnxsdp-env.sh; set -u; RUST_TEST_THREADS=1 TEST_DEVICE_ADDR=172.31.1.11:12345 ./x.py --stage 2 test $(ferrocene/ci/split-tasks.py << parameters.job >>) --ferrocene-test-one-crate-per-cargo-call
    steps:
      - aws-oidc-auth
      - ferrocene-checkout
      - setup-venv
      - setup-qnx-toolchain:
          source-env-script: false
      - ferrocene-job-test-vm:
          checkout-source: false
          docker-image-tag: << pipeline.parameters.docker-image-tag--x86_64--ubuntu-20 >>
          run-emulator-docker-image-tag: << pipeline.parameters.docker-image-tag--x86_64--ubuntu-24 >>
          restore-from-job: x86_64-linux-build
          emulator-script: "set +u; source ./qnx710-472/qnxsdp-env.sh; set -u; ./ferrocene/ci/scripts/emulated-x86_64-qnx-test-runner.sh"

  aarch64-qnx-generic-test-vm:
    executor: linux-vm
    parameters:
      job:
        type: string
      resource-class:
        type: string
    resource_class: << parameters.resource-class >>
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
      FERROCENE_TARGETS: aarch64-unknown-nto-qnx710
      SCRIPT: |
        set +u; source ./qnx710-472/qnxsdp-env.sh; set -u; RUST_TEST_THREADS=1 TEST_DEVICE_ADDR=172.31.1.105:12345 ./x.py --stage 2 test $(ferrocene/ci/split-tasks.py << parameters.job >>) --ferrocene-test-one-crate-per-cargo-call
    steps:
      - aws-oidc-auth
      - ferrocene-checkout
      - setup-venv
      - setup-qnx-toolchain:
          source-env-script: false
      - ferrocene-job-test-vm:
          checkout-source: false
          docker-image-tag: << pipeline.parameters.docker-image-tag--x86_64--ubuntu-20 >>
          run-emulator-docker-image-tag: << pipeline.parameters.docker-image-tag--x86_64--ubuntu-24 >>
          restore-from-job: x86_64-linux-build
          emulator-script: "set +u; source ./qnx710-472/qnxsdp-env.sh; set -u; ./ferrocene/ci/scripts/emulated-aarch64-qnx-test-runner.sh"

  # aarch64-unknown-linux-gnu jobs

  aarch64-linux-llvm:
    executor: docker-aarch64-ubuntu-20
    resource_class: arm.xlarge # 8-core
    environment:
      FERROCENE_HOST: aarch64-unknown-linux-gnu
      SCRIPT: ferrocene/ci/scripts/llvm_cache.py prepare
      # This tries to strike a balance between the highest concurrency possible
      # and not running out of memory during a build. If building LLVM fails
      # due to the OOM killer killing the build, decrease this number.
      LLVM_BUILD_PARALLELISM: 18
    steps:
      - when:
          condition: << pipeline.parameters.llvm-rebuild--aarch64-unknown-linux-gnu >>
          steps:
            - aws-oidc-auth
            - ferrocene-checkout
            - ferrocene-ci
      - run:
          name: Empty step to make sure the job always has steps
          command: echo

  aarch64-linux-build:
    executor: docker-aarch64-ubuntu-20
    resource_class: arm.xlarge # 8-core
    environment:
      FERROCENE_HOST: aarch64-unknown-linux-gnu
      FERROCENE_TARGETS: << pipeline.parameters.targets--aarch64-unknown-linux-gnu--build >>
      SCRIPT: |
        ferrocene/ci/scripts/llvm_cache.py download
        ./x.py --stage 2 build library src/tools/rustdoc
        ./x.py --stage 1 build src/tools/rustdoc
    steps: [ferrocene-job-build]

  aarch64-linux-dist:
    executor: docker-aarch64-ubuntu-20
    resource_class: arm.xlarge # 8-core
    environment:
      FERROCENE_HOST: aarch64-unknown-linux-gnu
      SCRIPT: |
        # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
        ./x.py --stage 2 dist $(ferrocene/ci/split-tasks.py dist)
    steps:
      - ferrocene-job-dist:
          restore-from-job: aarch64-linux-build

  aarch64-linux-dist-tools:
    executor: docker-aarch64-ubuntu-20
    resource_class: arm.xlarge # 8-core
    environment:
      FERROCENE_HOST: aarch64-unknown-linux-gnu
      SCRIPT: |
        # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
        ./x.py --stage 2 dist $(ferrocene/ci/split-tasks.py dist:tools)
    steps:
      - ferrocene-job-dist:
          restore-from-job: aarch64-linux-build

  aarch64-linux-self-test:
    executor: docker-aarch64-ubuntu-20
    resource_class: arm.medium # 2-core
    environment:
      FERROCENE_HOST: aarch64-unknown-linux-gnu
      FERROCENE_TARGETS: << pipeline.parameters.targets--aarch64-unknown-linux-gnu--self-test >>
    steps:
      - aws-oidc-auth
      - ferrocene-git-shallow-clone:
          depth: 1
      - run:
          name: Download dist artifacts and run the self-test tool
          command: ferrocene/ci/scripts/run-self-test.sh

  # aarch64-apple-darwin jobs

  aarch64-darwin-llvm:
    macos:
      xcode: "15.3.0"
    resource_class: macos.m1.large.gen1 # 8 cores
    environment:
      FERROCENE_HOST: aarch64-apple-darwin
      FERROCENE_TARGETS: aarch64-apple-darwin,x86_64-apple-darwin
      SCRIPT: ferrocene/ci/scripts/llvm_cache.py prepare
      # This tries to strike a balance between the highest concurrency possible
      # and not running out of memory during a build. If building LLVM fails
      # due to using too much memory, decrease this number.
      LLVM_BUILD_PARALLELISM: 18
    steps:
      - when:
          condition: << pipeline.parameters.llvm-rebuild--aarch64-apple-darwin >>
          steps:
            - ferrocene-checkout
            - ferrocene-setup-darwin # Darwin does not come with awscli, setup it before aws steps
            - setup-venv
            - aws-oidc-auth
            - ferrocene-ci
      - run:
          name: Empty step to make sure the job always has steps
          command: echo

  aarch64-darwin-build:
    macos:
      xcode: "15.3.0"
    resource_class: macos.m1.large.gen1 # 8 cores
    environment:
      FERROCENE_HOST: aarch64-apple-darwin
      FERROCENE_TARGETS: << pipeline.parameters.targets--aarch64-apple-darwin--build >>
      SCRIPT: |
        ferrocene/ci/scripts/llvm_cache.py download
        ./x.py --stage 2 build library src/tools/rustdoc
        ./x.py --stage 1 build src/tools/rustdoc
    steps:
      - ferrocene-job-build:
          os: darwin

  aarch64-darwin-dist:
    macos:
      xcode: "15.3.0"
    resource_class: macos.m1.large.gen1 # 8 cores
    environment:
      FERROCENE_HOST: aarch64-apple-darwin
      FERROCENE_TARGETS: << pipeline.parameters.targets--aarch64-apple-darwin--build >>
      SCRIPT: |
        # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
        ./x.py --stage 2 dist $(ferrocene/ci/split-tasks.py dist)
        ./x.py --stage 2 dist rust-std
    steps:
      - ferrocene-job-dist:
          os: darwin
          restore-from-job: aarch64-darwin-build

  aarch64-darwin-dist-tools:
    macos:
      xcode: "15.3.0"
    resource_class: macos.m1.large.gen1 # 8 cores
    environment:
      FERROCENE_HOST: aarch64-apple-darwin
      FERROCENE_TARGETS: << pipeline.parameters.targets--aarch64-apple-darwin--build >>
      SCRIPT: |
        # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
        ./x.py --stage 2 dist $(ferrocene/ci/split-tasks.py dist:tools)
    steps:
    - ferrocene-job-dist:
          os: darwin
          restore-from-job: aarch64-darwin-build

  aarch64-darwin-self-test:
    macos:
      xcode: "15.3.0"
    resource_class: macos.m1.medium.gen1 # 4 cores
    environment:
      FERROCENE_HOST: aarch64-apple-darwin
      FERROCENE_TARGETS: << pipeline.parameters.targets--aarch64-apple-darwin--self-test >>
    steps:
      - ferrocene-git-shallow-clone:
          depth: 1
      - ferrocene-setup-darwin # Darwin does not come with awscli, setup it before aws steps
      - aws-oidc-auth
      - run:
          name: Download dist artifacts and run the self-test tool
          command: ferrocene/ci/scripts/run-self-test.sh

  aarch64-darwin-generic-test-runner:
    macos:
      xcode: "15.3.0"
    parameters:
      job:
        type: string
      resource-class:
        type: string
    resource_class: << parameters.resource-class >>
    environment:
      FERROCENE_HOST: aarch64-apple-darwin
      SCRIPT: |
        # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
        ./x.py --stage 2 test $(ferrocene/ci/split-tasks.py << parameters.job >>) --ferrocene-test-one-crate-per-cargo-call
    steps:
      - ferrocene-job-test-container:
          os: darwin
          restore-from-job: aarch64-darwin-build

  # x86_64-pc-windows-msvc jobs

  x86_64-windows-llvm:
    executor:
      name: win/server-2022
      size: large # 8-core
      shell: bash.exe -euo pipefail
    environment:
      FERROCENE_BUILD_HOST: x86_64-pc-windows-msvc
      FERROCENE_HOST: x86_64-pc-windows-msvc
      # On Windows, the virtualenv detection seems to struggle at times, give it a kick
      SCRIPT: |
        export VIRTUAL_ENV=$HOME/.venv
        export PATH=$HOME/.venv/Scripts:$PATH
        $HOME/.venv/Scripts/python.exe ferrocene/ci/scripts/llvm_cache.py prepare
      # This tries to strike a balance between the highest concurrency possible
      # and not running out of memory during a build. If building LLVM fails
      # due to the OOM killer killing the build, decrease this number.
      LLVM_BUILD_PARALLELISM: 18
    steps:
      - run:
          name: Make sure git autocrlf is false
          command: git config --global core.autocrlf false
      - when:
          condition: << pipeline.parameters.llvm-rebuild--x86_64-pc-windows-msvc >>
          steps:
            - aws-oidc-auth
            - ferrocene-checkout
            - ferrocene-setup-windows
            - setup-venv
            - ferrocene-ci
      - run:
          name: Empty step to make sure the job always has steps
          command: echo

  # This job caused us to extend our CircleCI TTL via
  # https://support.circleci.com/hc/en-us/articles/17136864790299-How-to-configure-your-OIDC-token-s-TTL-at-the-Organization-and-Project-Levels
  x86_64-windows-dist:
    executor:
      name: win/server-2022
      size: large # 8-core
      shell: bash.exe -euo pipefail
    environment:
      FERROCENE_BUILD_HOST: x86_64-pc-windows-msvc
      FERROCENE_HOST: x86_64-pc-windows-msvc
      FERROCENE_TARGETS: << pipeline.parameters.targets--x86_64-pc-windows-msvc--build >>
      # On Windows, the virtualenv detection seems to struggle at times, give it a kick
      SCRIPT: |
        export VIRTUAL_ENV=$HOME/.venv
        export PATH=$HOME/.venv/Scripts:$PATH
        $HOME/.venv/Scripts/python.exe ferrocene/ci/scripts/llvm_cache.py download
        # See ferrocene/ci/split-tasks.py for a list of tasks executed by this.
        ./x.py --stage 2 dist $($HOME/.venv/Scripts/python.exe ferrocene/ci/split-tasks.py dist)
        ./x.py --stage 2 dist $($HOME/.venv/Scripts/python.exe ferrocene/ci/split-tasks.py dist:tools)
        ./x.py --stage 2 dist rust-std
    steps:
      - ferrocene-job-dist:
          os: windows

  x86_64-windows-self-test:
    executor:
      name: win/server-2022
      size: medium # 4-core
      shell: bash.exe -euo pipefail
    environment:
      FERROCENE_BUILD_HOST: x86_64-pc-windows-msvc
      FERROCENE_HOST: x86_64-pc-windows-msvc
      FERROCENE_TARGETS: << pipeline.parameters.targets--x86_64-pc-windows-msvc--self-test >>
    steps:
      - ferrocene-git-shallow-clone:
          depth: 1
      - aws-oidc-auth
      - ferrocene-setup-windows
      - setup-venv
      - setup-qnx-toolchain: {}
      - run:
          name: Download dist artifacts and run the self-test tool
          command: ferrocene/ci/scripts/run-self-test.sh

  finish-build:
    executor: docker-x86_64-ubuntu-20
    resource_class: small # 1-core
    environment:
      FERROCENE_HOST: x86_64-unknown-linux-gnu
    steps:
      - aws-oidc-auth
      - ferrocene-git-shallow-clone:
          depth: 1
      - run:
          name: Restore files from the x86_64-linux-build
          command: ferrocene/ci/scripts/persist-between-jobs.sh restore x86_64-linux-build
      - run:
          name: Configure
          command: ferrocene/ci/configure.sh
      - run:
          name: Checkout the submodules
          command: ferrocene/ci/scripts/checkout-submodules.sh
      - run:
          name: Generate build metadata
          command: ./x.py dist ferrocene-build-metadata
      - run:
          name: Upload metadata files to S3
          command: ferrocene/ci/scripts/upload-dist-artifacts.sh

  # Simple job used to run "something" when no other jobs are supposed to be
  # run. See the `skip` workflow for more information.
  skip:
    executor: docker-x86_64-ubuntu-20
    resource_class: small # 1-core
    steps:
      - run:
          name: This is a workaround for CircleCI always wanting at least a job per commit.
          command: "true"
      - run:
          name: This job does nothing!
          command: "true"

  # Job to build and upload a Docker image defined ferrocene/ci/docker-images.
  # If the image exists in the remote storage and is up to date, the job will
  # early exit without doing any work.
  build-docker-x86_64:
    description: Job that builds and uploads a Docker image on an x86_64 host, if needed.
    docker:
      - image: cimg/base:current
    resource_class: large # 4-core
    parameters:
      image:
        description: The image that needs to be built
        type: string
      tag:
        description: The tag of the image that needs to be build
        type: string
      rebuild:
        description: Whether the image should be rebuilt or not
        type: boolean
    steps:
      - when:
          condition: << parameters.rebuild >>
          steps:
            - aws-cli/install
            - aws-oidc-auth
            - ferrocene-git-shallow-clone:
                depth: 1
            - setup_remote_docker:
                version: default
            - run:
                name: Build and upload the Docker image, if needed
                command: ferrocene/ci/scripts/build-docker-image.sh
                environment:
                  IMAGE_NAME: << parameters.image >>
                  IMAGE_TAG: << parameters.tag >>
      - run:
          name: Empty step to make sure the job always has steps
          command: echo

  build-docker-aarch64:
    description: Job that builds and uploads a Docker image on an aarch64 host, if needed.
    docker:
      - image: cimg/base:current
    resource_class: arm.medium # 2-core
    parameters:
      image:
        description: The image that needs to be built
        type: string
      tag:
        description: The tag of the image that needs to be build
        type: string
      rebuild:
        description: Whether the image should be rebuilt or not
        type: boolean
    steps:
      - when:
          condition: << parameters.rebuild >>
          steps:
            - aws-cli/install
            - aws-oidc-auth
            - ferrocene-git-shallow-clone:
                depth: 1
            - setup_remote_docker:
                version: default # Only default and edge are supported: https://circleci.com/docs/building-docker-images/#docker-version
            - run:
                name: Build and upload the Docker image, if needed
                command: ferrocene/ci/scripts/build-docker-image.sh
                environment:
                  IMAGE_NAME: << parameters.image >>
                  IMAGE_TAG: << parameters.tag >>
      - run:
          name: Empty step to make sure the job always has steps
          command: echo

workflows:
  version: 2

  # Main workflow used by bors to ensure every PR is fully green.
  full:
    when:
      or:
        - equal: [<< pipeline.git.branch >>, "staging"]
        - equal: [<< pipeline.git.branch >>, "trying"]
    jobs:
      - build-docker-x86_64:
          name: build-docker--ubuntu-20--x86_64
          image: ubuntu-20
          tag: << pipeline.parameters.docker-image-tag--x86_64--ubuntu-20 >>
          rebuild: << pipeline.parameters.docker-image-rebuild--ci-docker-images--x86_64--ubuntu-20 >>

      - build-docker-aarch64:
          name: build-docker--ubuntu-20--aarch64
          image: ubuntu-20
          tag: << pipeline.parameters.docker-image-tag--aarch64--ubuntu-20 >>
          rebuild: << pipeline.parameters.docker-image-rebuild--ci-docker-images--aarch64--ubuntu-20 >>

      - misc-checks:
          requires:
            - build-docker--ubuntu-20--x86_64

      - x86_64-linux-llvm:
          requires:
            - build-docker--ubuntu-20--x86_64
      - x86_64-linux-build:
          requires:
            - x86_64-linux-llvm
      - x86_64-linux-docs:
          requires: &test-outcomes-dependencies
            # Need to depend on all of the test builders to include test
            # outcomes in the qualification documents.
            - misc-checks
            - x86_64-linux-test
            - x86_64-linux-test-library
            - x86_64-linux-test-library-std
            - x86_64-linux-compiletest
            - x86_64-qnx-test-library
            - x86_64-qnx-test-library-std
            - x86_64-qnx-test-compiletest
            - aarch64-qnx-test-library
            - aarch64-qnx-test-library-std
            - aarch64-qnx-test-compiletest
            - aarch64-linux-test-library
            - aarch64-linux-compiletest
      - x86_64-linux-traceability-matrix:
          requires: *test-outcomes-dependencies
      - x86_64-linux-dist:
          requires:
            - x86_64-linux-build
      - x86_64-linux-dist-tools:
          requires:
            - x86_64-linux-build
      - x86_64-linux-dist-targets:
          requires:
            - x86_64-linux-build
      - x86_64-linux-dist-src:
          requires:
            - x86_64-linux-build
      - x86_64-linux-generic-test-container:
          name: x86_64-linux-test
          job: test
          resource-class: large # 4-core
          requires:
            - x86_64-linux-build
      - x86_64-linux-generic-test-container:
          name: x86_64-linux-test-library
          job: test:library
          resource-class: large # 4-core
          requires:
            - x86_64-linux-build
      - x86_64-linux-generic-test-container:
          name: x86_64-linux-compiletest
          job: test:compiletest
          resource-class: xlarge # 8-core
          requires:
            - x86_64-linux-build
      - x86_64-linux-test-library-std:
          requires:
            - x86_64-linux-build

      - aarch64-linux-generic-test-vm:
          name: aarch64-linux-compiletest
          job: test:compiletest
          resource-class: large # 4-core
          requires:
            - x86_64-linux-build
      - aarch64-linux-generic-test-vm:
          name: aarch64-linux-test-library
          job: test:library
          resource-class: large # 4-core
          requires:
            - x86_64-linux-build

      - wasm-dist-oxidos:
          requires:
            - x86_64-linux-build

      - x86_64-linux-self-test:
          requires:
            - x86_64-linux-dist
            - x86_64-linux-dist-tools
            - x86_64-linux-dist-targets
            - aarch64-linux-dist

      - x86_64-qnx-generic-test-vm:
          name: x86_64-qnx-test-library
          job: test:library
          resource-class: large # 4-core
          requires:
            - x86_64-linux-build

      - x86_64-qnx-generic-test-vm:
          name: x86_64-qnx-test-library-std
          job: test:library-std
          resource-class: large # 4-core
          requires:
            - x86_64-linux-build

      - x86_64-qnx-generic-test-vm:
          name: x86_64-qnx-test-compiletest
          job: qnx:compiletest-no-only-hosts
          resource-class: xlarge # 8-core
          requires:
            - x86_64-linux-build

      - aarch64-qnx-generic-test-vm:
          name: aarch64-qnx-test-library
          job: test:library
          resource-class: large # 4-core
          requires:
            - x86_64-linux-build

      - aarch64-qnx-generic-test-vm:
          name: aarch64-qnx-test-library-std
          job: test:library-std
          resource-class: large # 4-core
          requires:
            - x86_64-linux-build

      - aarch64-qnx-generic-test-vm:
          name: aarch64-qnx-test-compiletest
          job: qnx:compiletest-no-only-hosts
          resource-class: xlarge # 8-core
          requires:
            - x86_64-linux-build

      - aarch64-linux-llvm:
          requires:
            - build-docker--ubuntu-20--aarch64
      - aarch64-linux-build:
          requires:
            - aarch64-linux-llvm
      - aarch64-linux-dist:
          requires:
            - aarch64-linux-build
      - aarch64-linux-dist-tools:
          requires:
            - aarch64-linux-build
      - aarch64-linux-self-test:
          requires:
            - aarch64-linux-dist
            - aarch64-linux-dist-tools
            - x86_64-linux-dist-targets
            - x86_64-linux-dist

      - aarch64-darwin-llvm: {}
      - aarch64-darwin-build:
          requires:
            - aarch64-darwin-llvm
      - aarch64-darwin-dist:
          requires:
            - aarch64-darwin-build
      - aarch64-darwin-dist-tools:
          requires:
            - aarch64-darwin-build
      - aarch64-darwin-generic-test-runner:
          name: aarch64-darwin-test
          job: test
          resource-class: macos.m1.large.gen1 # 8 cores
          requires:
            - aarch64-darwin-build
      - aarch64-darwin-generic-test-runner:
          name: aarch64-darwin-test-library
          job: test:library
          resource-class: macos.m1.large.gen1 # 8 cores
          requires:
            - aarch64-darwin-build
      - aarch64-darwin-generic-test-runner:
          name: aarch64-darwin-compiletest
          job: test:compiletest
          resource-class: macos.m1.large.gen1 # 8 cores
          requires:
            - aarch64-darwin-build
      - aarch64-darwin-generic-test-runner:
          name: aarch64-darwin-test-library-std
          job: test:library-std
          resource-class: macos.m1.large.gen1 # 8 cores
          requires:
            - aarch64-darwin-build
      - aarch64-darwin-self-test:
          requires:
            - aarch64-darwin-dist
            - aarch64-darwin-dist-tools
            - x86_64-linux-dist-targets

      - x86_64-windows-llvm: {}
      - x86_64-windows-dist:
          requires:
            - x86_64-windows-llvm
      - x86_64-windows-self-test:
          requires:
            - x86_64-windows-dist
            - x86_64-linux-dist-targets

      - finish-build:
          requires:
            - x86_64-linux-docs
            - x86_64-linux-dist-src
            - x86_64-linux-traceability-matrix
            - x86_64-linux-self-test
            - x86_64-windows-self-test
            - wasm-dist-oxidos
            - aarch64-linux-self-test
            - aarch64-darwin-self-test
            - aarch64-darwin-test
            - aarch64-darwin-test-library
            - aarch64-darwin-test-library-std
            - aarch64-darwin-compiletest

  # CircleCI doesn't like a build when no jobs are actually executed, treating
  # it as a build failure. Due to how our workflows are setup this will happen
  # for the branches bors lands code in, as those branches are not meant to run
  # any test. To work around the issue this workflow starts a simple job doing
  # nothing when a build for those branches is requested.
  skip:
    when:
      or:
        # These branches are excluded from all the other workflows:
        - equal: [<< pipeline.git.branch >>, "staging.tmp"]
        - equal: [<< pipeline.git.branch >>, "staging-squash-merge.tmp"]
        - equal: [<< pipeline.git.branch >>, "trying.tmp"]
        - equal: [<< pipeline.git.branch >>, "main"]
        - matches:
            pattern: "^release\\/.*"
            value: << pipeline.git.branch >>
    jobs:
      - skip

commands:
  ferrocene-job-build:
    description: Collection of steps for build jobs
    parameters:
      os:
        type: string
        default: linux # Or `windows` or `darwin`
    steps:
      - ferrocene-checkout:
          llvm-subset: true
      - when:
          condition:
            equal: [<<parameters.os>>, "darwin"]
          steps:
            - ferrocene-setup-darwin
            - setup-venv
      - when:
          condition:
            equal: [<<parameters.os>>, "windows"]
          steps:
            - ferrocene-setup-windows
            - setup-venv
      - aws-oidc-auth
      - ferrocene-ci
      # Persist the build artifacts so following jobs don't have to start from
      # scratch. The build directory is shrinked beforehand to avoid persisting
      # too much data (slowing down uploads and downloads).
      - run:
          name: Shrink the build directory before persisting it
          command: ferrocene/ci/scripts/shrink-build-directory.sh
      - run:
          name: Persist build output between jobs
          command: ferrocene/ci/scripts/persist-between-jobs.sh upload ./build

  ferrocene-job-dist:
    description: Collection of steps for dist jobs
    parameters:
      os:
        type: string
        default: linux # Or `windows` or `darwin`
      restore-from-job:
        type: string
        default: ""
      llvm-subset:
        type: boolean
        default: true
      qnx:
        type: boolean
        default: false
    steps:
      - ferrocene-checkout:
          llvm-subset: << parameters.llvm-subset >>
      - when:
          condition:
            equal: [<<parameters.os>>, "darwin"]
          steps:
            - ferrocene-setup-darwin
            - setup-venv
      - when:
          condition:
            equal: [<<parameters.os>>, "windows"]
          steps:
            - ferrocene-setup-windows
            - setup-venv
      - aws-oidc-auth
      - when:
          condition:  <<parameters.restore-from-job>>
          steps:
            - run:
                name: Restore files from the << parameters.restore-from-job >> job
                command: ferrocene/ci/scripts/persist-between-jobs.sh restore << parameters.restore-from-job >>
      - when:
          condition:
            equal: [<<parameters.qnx>>, true]
          steps:
            - setup-qnx-toolchain: {}
      - ferrocene-ci

  ferrocene-job-test-container:
    description: Collection of steps for test jobs in containers
    parameters:
      restore-from-job:
        type: string
      os:
        type: string
        default: linux # Or `windows` or `darwin`
    steps:
      - ferrocene-checkout:
          llvm-subset: true
      - when:
          condition:
            equal: [<<parameters.os>>, "darwin"]
          steps:
            - ferrocene-setup-darwin  # Darwin does not come with awscli, setup it before aws steps
      - aws-oidc-auth
      - run:
          name: Restore files from the << parameters.restore-from-job >> job
          command: ferrocene/ci/scripts/persist-between-jobs.sh restore << parameters.restore-from-job >>
      - ferrocene-ci

  ferrocene-job-test-vm:
    description: Collection of steps for test jobs in VMs
    # a separate Docker image can be used to run a newer version of e.g. QEMU than
    # the version available in `docker-image-tag`
    parameters:
      # the "preparing the emulator" and other steps will run in this Docker image
      docker-image-tag:
        type: string
      # the "running the emulator" step will run in this Docker image
      run-emulator-docker-image-tag:
        type: string
      restore-from-job:
        type: string
      emulator-script:
        type: string
        default: ""
      checkout-source:
        type: boolean
        default: true
    steps:
      - aws-oidc-auth
      - when:
          condition: << parameters.checkout-source >>
          steps:
            - ferrocene-checkout:
                llvm-subset: true
      - run:
          name: Restore files from the << parameters.restore-from-job >> job
          command: ferrocene/ci/scripts/persist-between-jobs.sh restore << parameters.restore-from-job >>
      - run:
          name: Enable IPv6 for Docker
          command: |
            sudo mkdir -p /etc/docker
            cat \<<EOF | sudo tee /etc/docker/daemon.json
            {
              "ipv6": true,
              "fixed-cidr-v6": "2001:db8:1::/64"
            }
            EOF
            sudo service docker restart

      - run:
          name: Pull the Docker image used for CI
          command: |
            aws ecr get-login-password --region us-east-1 \
              | docker login -u AWS --password-stdin << pipeline.parameters.docker-repository-url--ci-docker-images >>
            docker pull << pipeline.parameters.docker-repository-url--ci-docker-images >>:<< parameters.docker-image-tag >>
            docker pull << pipeline.parameters.docker-repository-url--ci-docker-images >>:<< parameters.run-emulator-docker-image-tag >>

      - when:
          condition: << parameters.emulator-script >>
          steps:
            - run:
                name: Create emulator directory
                command: mkdir /tmp/emulator

            - run:
                name: Prepare emulator
                command: |
                  docker run \
                    --rm \
                    $(python3 -c "import os; print(' '.join('--env ' + var for var in os.environ if var not in ['HOME', 'LANG', 'SUDO_USER']))") \
                    -e SCRIPT="<< parameters.emulator-script >> prepare" \
                    -e REMOTE_TEST_SERVER_STAGE=2 \
                    --workdir /home/ci/project \
                    --volume $(pwd):/home/ci/project \
                    --volume /tmp/emulator:/tmp/emulator \
                    --user $(id -u):$(id -g) \
                    --network host \
                    --privileged \
                    --interactive \
                    --tty \
                    << pipeline.parameters.docker-repository-url--ci-docker-images >>:<< parameters.docker-image-tag >> \
                    ferrocene/ci/run.sh
                    # Actual command set in -e SCRIPT=... above!

            - run:
                name: Execute emulator in the background
                background: true
                command: |
                  docker run \
                    --rm \
                    $(python3 -c "import os; print(' '.join('--env ' + var for var in os.environ if var not in ['HOME', 'LANG', 'SUDO_USER', 'PATH', 'VIRTUAL_ENV']))") \
                    --workdir /home/ci/project \
                    --volume $(pwd):/home/ci/project \
                    --volume /tmp/emulator:/tmp/emulator \
                    --user $(id -u):$(id -g) \
                    --network host \
                    --privileged \
                    --interactive \
                    --tty \
                    << pipeline.parameters.docker-repository-url--ci-docker-images >>:<< parameters.run-emulator-docker-image-tag >> \
                    bash -c "<< parameters.emulator-script >>"

      - ferrocene-ci:
          wrapper: |
            docker run \
              --rm \
              $(python3 -c "import os; print(' '.join('--env ' + var for var in os.environ if var not in ['HOME', 'LANG', 'SUDO_USER', 'PATH', 'VIRTUAL_ENV']))") \
              --workdir /home/ci/project \
              --volume $(pwd):/home/ci/project \
              --volume /tmp/emulator:/tmp/emulator \
              --user $(id -u):$(id -g) \
              --network host \
              --interactive \
              --tty \
              << pipeline.parameters.docker-repository-url--ci-docker-images >>:<< parameters.docker-image-tag >> \

  ferrocene-git-shallow-clone:
    description: Perform a shallow `git clone`
    parameters:
      depth:
        type: integer
    steps:
      - run:
          name: Clone the source code
          command: |
            # There is no need to use any deploy key or SSH for CI, as the
            # Ferrocene repository is public anyway. Also, on Windows the
            # deploy key doesn't seem to be injected into the VM, so using
            # HTTPS fixes that problem too.
            repo_url="$(echo "${CIRCLE_REPOSITORY_URL}" | sed 's#^git@github.com:#https://github.com/#')"

            git init .
            git remote add origin "${repo_url}"
            git fetch --depth=<< parameters.depth >> origin "${CIRCLE_SHA1}"
            git checkout -b "${CIRCLE_BRANCH}" "${CIRCLE_SHA1}"

  ferrocene-setup-darwin:
    description: Prepare the Darwin environment
    steps:
      - run:
          name: Setup Darwin environment
          command: ferrocene/ci/scripts/setup-darwin.sh
          

  ferrocene-setup-windows:
    description: Prepare the Windows environment
    steps:
      - run:
          name: Setup Windows environment
          command: ferrocene/ci/scripts/setup-windows.sh

  # This task can be skipped inside docker containers, it's mainly intended for Mac/Windows hosts.
  setup-venv:
    description: Setup uv and the Python venv
    steps:
      - run:
          name: Setup uv and the Python venv
          command: ferrocene/ci/scripts/setup-venv.sh

  ferrocene-checkout:
    description: Checkout the Ferrocene source code
    parameters:
      llvm-subset:
        type: boolean
        default: false
    steps:
      - ferrocene-git-shallow-clone:
          depth: 2
      - when:
          condition: << parameters.llvm-subset >>
          steps:
            - run:
                name: Clone a subset of the llvm-project monorepo
                command: ferrocene/ci/scripts/clone-llvm-subset.sh
      - run:
          name: Checkout the submodules
          command: ferrocene/ci/scripts/checkout-submodules.sh
      - run:
          name: Unshallow the clone on the beta channel
          command: ferrocene/ci/scripts/unshallow-on-beta.sh
      - run:
          name: Change the files modification time to a consistent date
          command: ferrocene/ci/scripts/reset-mtime-to-last-commit.sh
      - run:
          name: Show the current environment
          command: ferrocene/ci/scripts/show-environment.sh

  ferrocene-ci:
    description: Common CI steps for Ferrocene
    parameters:
      wrapper:
        type: string
        default: ""
    steps:
      - run:
          name: Execute the build
          command: << parameters.wrapper >> ferrocene/ci/run.sh

      - run:
          name: Generate resource usage report
          when: always
          command: |
            mkdir -p /tmp/metrics
            ferrocene/ci/scripts/generate-resources-usage-report.py build/metrics.json > /tmp/metrics/report.html
            cp build/metrics.json /tmp/metrics/raw.json

      - run:
          name: Upload artifacts to S3
          command: ferrocene/ci/scripts/upload-dist-artifacts.sh
          # We want to upload artifacts even when the build is failing, to be
          # able to retrieve and investigate them. They won't be making into a
          # release anyway, sine the "finish-build" job will not be executed in
          # case of a failure.
          when: always

      - store_artifacts:
          path: /tmp/metrics
          destination: metrics

  setup-qnx-toolchain:
    description: Setup QNX Toolchain
    parameters:
      source-env-script:
        type: boolean
        default: true
    steps:
      - run:
          name: Fetch QNX710 toolchain
          # On Windows, the virtualenv detection seems to struggle at times.
          command: |
            if [[ "${OSTYPE}" = "msys" ]]; then
                source $HOME/.venv/Scripts/activate
            else
                source $HOME/.venv/bin/activate
            fi
            python ferrocene/ci/scripts/cache.py retrieve s3://ferrocene-ci-mirrors/manual/qnx/qnx710-472-deployment.tar.zst .
      - when:
          condition: << parameters.source-env-script >>
          steps:
            - run:
                name: Set PATH to include QNX710 tools
                command: echo 'source $(pwd)/qnx710-472/qnxsdp-env.sh' >> "$BASH_ENV"
      - run:
          name: Test qcc
          command: qcc -v || true

  aws-oidc-auth:
    description: Authenticate with AWS using OIDC
    steps:
      - run:
          name: Prepare environment for AWS authentication
          command: |
            # Load the JWT token into a file
            touch /tmp/awsjwt
            chmod 0600 /tmp/awsjwt
            echo "${CIRCLE_OIDC_TOKEN_V2}" > /tmp/awsjwt

            set_env() {
              echo "export $1=\"$2\"" >> "${BASH_ENV}"
            }

            # Set environment variables to authenticate with OIDC
            set_env AWS_WEB_IDENTITY_TOKEN_FILE /tmp/awsjwt
            set_env AWS_ROLE_SESSION_NAME circleci
            set_env AWS_DEFAULT_REGION us-east-1

            # Avoid reaching out to the EC2 metadata server, which just
            # timeouts outside of EC2.
            set_env AWS_EC2_METADATA_DISABLED true

            # Some versions of AWS CLI fail if `less` is not installed, so
            # disable pager support to suppress the error.
            set_env AWS_PAGER ""

      - run:
          name: Authenticate with AWS
          command: aws sts get-caller-identity

executors:
  docker-x86_64-ubuntu-20:
    docker:
      - image: << pipeline.parameters.docker-repository-url--ci-docker-images >>:<< pipeline.parameters.docker-image-tag--x86_64--ubuntu-20 >>
        aws_auth:
          oidc_role_arn: $AWS_ROLE_ARN
  docker-aarch64-ubuntu-20:
    docker:
      - image: << pipeline.parameters.docker-repository-url--ci-docker-images >>:<< pipeline.parameters.docker-image-tag--aarch64--ubuntu-20 >>
        aws_auth:
          oidc_role_arn: $AWS_ROLE_ARN
  docker-x86_64-ubuntu-24:
    docker:
      - image: << pipeline.parameters.docker-repository-url--ci-docker-images >>:<< pipeline.parameters.docker-image-tag--x86_64--ubuntu-24 >>
        aws_auth:
          oidc_role_arn: $AWS_ROLE_ARN
  docker-aarch64-ubuntu-24:
    docker:
      - image: << pipeline.parameters.docker-repository-url--ci-docker-images >>:<< pipeline.parameters.docker-image-tag--aarch64--ubuntu-24 >>
        aws_auth:
          oidc_role_arn: $AWS_ROLE_ARN
  linux-vm:
    machine:
      image: default
